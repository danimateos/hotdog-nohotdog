{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My First Hotdog detector\n",
    "\n",
    "Hi there! Welcome back to this series on Deep Learning for image classification. In the two previous installments about [imagenet and deep learning], and [the train-test split], we managed to get the images we need to build a [sweet sweet hotdog/nohotdog classifier] using [Deep Learning]. This time, we are finally going to play around with Convolutional Neural Networks (CNNs)! But wait, what are those???\n",
    "\n",
    "[sweet sweet hotdog/nohotdog classifier]: https://www.youtube.com/watch?v=ACmydtFDTGs\n",
    "[Deep Learning]: https://en.wikipedia.org/wiki/Deep_learning\n",
    "[imagenet and deep learning]: http://mateos.io/blog/getting-some-hotdogs/\n",
    "[the train-test split]: http://mateos.io/blog/train-test-split/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "The form our classifier is going to take is the [Convolutional Neural Network (CNN)](). These have revolutionized image classification and a lot of other tasks. Remember the 2012 Imagenet challenge?? This is the innovation that changed everyting. \n",
    "\n",
    "As any other Neural Network, CNNs consist of a series of stacked layers. Each layer consists of a series of neurons. These are simply nodes in a network that hold a floating point value, called their __activation__. Each node in a layer is connected to the layer immediately below, and the connection has a __weight__ associated with it.\n",
    "\n",
    "The simplest kind of layer that we can think of is one in which each neuron is connected to __all__ the neurons in the preceding layer. This is called a [Dense](https://keras.io/layers/core/#dense) layer. In it, the activation of each neuron will be calculated from the sum of the activations of every single neuron in the previous layer, each multiplied by the corresponding weight. But that sum is not the activation itself; the activation will be calculated from that sum by applying an _activation function_.\n",
    "\n",
    "![Weights and activations](https://cdn-images-1.medium.com/max/479/1*QVIyc5HnGDWTNX3m-nIm9w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions\n",
    "\n",
    "As we have just seen, the connection between a neuron and the layer below is shaped by an _activation function_. This describes the relationship between the values in the preceding layer, the weights, and the activation value. For each neuron its activation $a_i$ will be determined by the expression:\n",
    "\n",
    "$$a_i = f(\\sum_j^n(a_i w_{ij}))$$ \n",
    "\n",
    "That $f$ is the activation function. There are a number of them that can be used without changing terribly how the NN performs. The requisites are basically:\n",
    "\n",
    "1. The activation function must be nonlinear. If it was, the whole network would be just a chain of matrix multiplications, and the output would be a linear function of the output. We could save all the trouble and just summarize the whole thing with a single multiplication. And, obviously, it wouldn't learn anything useful. The fun in NNs is that they are [Universal Function Approximators](http://neuralnetworksanddeeplearning.com/chap4.html).\n",
    "\n",
    "1. The activation function must be differentiable. That is crucial for our gradient descent (remember [the last post](TODO: internal link)): we need the derivative, the gradient, to know in what direction we need to push the weights in every step of the optimization.\n",
    "\n",
    "An early function that was widely used is the logistic function, the same used in logistic regression. If you think about it, then the expression above is exactly logistic regression. Therefore, a neural network can be thought of as a series of logistic regressions stacked one over the other!\n",
    "\n",
    "In reality, the current most used activation function is the [Rectified Linear Unit](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) (ReLu), but at this level the distinction is mostly academic. We don't need to go into the practical or theoretical differences between the ReLu and the logistic to get a general understanding of how NNs work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation\n",
    "\n",
    "In logistic regression, we pick the coefficients (corresponding to our _weights_ here) to minimize an error measure given a set of inputs and corresponding outputs. If we had an error measure here, we could adjust the weights so that the error measure for each input is minimized. But we do! it is the difference (measured in any of a number of ways) between the predictions of the network and the true classes. That will work for the last layer. \n",
    "\n",
    "What about the bottom layers? Well, if we had a perfect last hidden layer, then the previous one would have to predict its activations for a given input. Then, the error measure is the difference between the output of the previous and the \"perfect\" hidden layer! We can apply this reasoning to adjust the weights of each layer from the top to the bottom (back), for each layer in turn.\n",
    "\n",
    "Backpropagation is just that! A fancy way of saying: adjust by one step of gradient descent the last layer, then the second-to-last in view of those last layer weights, and so on until you reach the bottom. Rinse and repeat until you are satisfied with the results. This is the breakthrough that made neural networks trainable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "We've been talking about neural networks like there was only one kind. However, the recent explosion in Deep Learning performance and width of application is due in no small part to the invention of a variety of network kinds which are especially suited to particular tasks. In our specific application, image classification, and more generally in computer vision the kind that suits us best is the Convolutional Neural Network. This is a network that includes one or more [convolutional layers](https://keras.io/layers/convolutional/#conv2d).\n",
    "\n",
    "A convolutional layer differs from a dense layer in that each neuron in it doesn't look at the whole layer below it but only to a small region of it, often 3 x 3 or 5 x 5. That means that the first convolutional layer will look at squares of 9 or 25 pixels in much the same way that a neuron in a dense layer looks at its whole input layer. That results first in a huge reduction in number of parameters, which could explode with the kind of input sizes that an image classifier must handle - remember, each pixel in the image will result in three nodes in the input layer! this is a great bonus, but not the main point. The real advantages are:\n",
    "\n",
    "* Translation invariance: a neuron in a convolutional layer will learn to be activated in response to a particular visual feature. It will not care where that feature is: a neuron that recognizes vertical edges will recognize them anywhere in the image. \n",
    "\n",
    "* Hierarchy of features: I've mentioned the _first_ convolutional layer. What about the ones above it? Those will recognize to recognize features based on features: they will combine basic features (vertical or horizontal lines, for example) into more and more general features: grids, parallel arrays, then objects from the real world composed of those features.\n",
    "\n",
    "\n",
    "![Hierarhcy of features](https://cdn-images-1.medium.com/max/756/1*jl3je_hGCESg-G8dy3Z9Yg.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "\n",
    "Our work will be made sweet and easy by [Keras](https://keras.io/). Keras is just the kind of tool I love: it will let you do the most common operations quickly and easily, but it still gives you the power to go under the hood and have total control if you need it. It is a library built specifically for Deep Learning on Python by François Chollet and others. It runs on top of different backends, like Theano and Tensorflow. These are amazing libraries, but not the kind of thing that you want to deal with if you want to build your first prototype and iterate on it fast. You can think of the relationship between Keras and Tensorflow kind of like that between scikit-learn and numpy.\n",
    "\n",
    "![Keras](https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png)\n",
    "\n",
    "In order to follow the code below, you'll need to set up a working Keras environment. The easiest way to do so is probably to use [Google colab](https://colab.research.google.com/), a hosted notebook service which offers all relevant ML libraries preinstalled. They even offer free GPU acceleration! Just make sure you click on \"runtime\"/\"change runtime type\", then select \"GPU\" before you run the notebooks. They also offer [TPU](https://colab.research.google.com/notebooks/tpu.ipynb) acceleration for free! It's a bit more involved, so we'll just use GPUs for now.\n",
    "\n",
    "At this point we want to get our first classifier up and running, so let's get on with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting some hotdogs\n",
    "\n",
    "I've already done the hard, exhausting field work for you. If you are curious about how I did, check it out in the two previous installments, about [imagenet and deep learning], and [the train-test split].\n",
    "\n",
    "In order to save you the trouble of downloading and cleaning, I have made the data available [here](https://www.dropbox.com/s/dhpekpce05iev6a/data_v2.zip?dl=0). Run the following cell. It will download a zip file in the current folder.\n",
    "\n",
    "[imagenet and deep learning]: http://mateos.io/blog/getting-some-hotdogs/\n",
    "[the train-test split]: http://mateos.io/blog/train-test-split/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "FtwsDCijPqGL",
    "outputId": "2d6e1d8f-d60c-47e7-b078-55bf6bedba41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-02-26 12:25:31--  https://www.dropbox.com/s/dhpekpce05iev6a/data_v2.zip?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.68.1, 2620:100:6024:1::a27d:4401\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.68.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/dhpekpce05iev6a/data_v2.zip [following]\n",
      "--2019-02-26 12:25:32--  https://www.dropbox.com/s/raw/dhpekpce05iev6a/data_v2.zip\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucaaab87965e7ef9e3779b987b3f.dl.dropboxusercontent.com/cd/0/inline/AcHyiZuLgS_a0JMhdAjm9nbpICEsLFiXRsgQU7ln1MFwNRO4sC0c61YOo7jgAJym3JcKTtuNXV9_BLxa5RTTwbKnUw_vNACsgGalv1tG-bptlGZVdTDQVqeRa1l29kjYskI/file# [following]\n",
      "--2019-02-26 12:25:32--  https://ucaaab87965e7ef9e3779b987b3f.dl.dropboxusercontent.com/cd/0/inline/AcHyiZuLgS_a0JMhdAjm9nbpICEsLFiXRsgQU7ln1MFwNRO4sC0c61YOo7jgAJym3JcKTtuNXV9_BLxa5RTTwbKnUw_vNACsgGalv1tG-bptlGZVdTDQVqeRa1l29kjYskI/file\n",
      "Resolving ucaaab87965e7ef9e3779b987b3f.dl.dropboxusercontent.com (ucaaab87965e7ef9e3779b987b3f.dl.dropboxusercontent.com)... 162.125.68.6, 2620:100:6024:6::a27d:4406\n",
      "Connecting to ucaaab87965e7ef9e3779b987b3f.dl.dropboxusercontent.com (ucaaab87965e7ef9e3779b987b3f.dl.dropboxusercontent.com)|162.125.68.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: /cd/0/inline2/AcEPDBDsJ7Th6j5GRiZQ9tjkDmhBiq-me_YmKACJtJ6BQcOxwGjIwjYrlof74gt1rzCv8Q951mDlCd6jLV6r0cWbrz2Oc_fZczOUrIBXAInLIuNYBAL-1bhlvMmMNteg43yh27RSsUTH10zXVVljW9ZU2WvsLX99bwENfnQtpMjZLaG_8qH4zsGJ2qeP6_P4lxVGmfualrJautpBtUJmEZ88QYlk5187QSnPHCtLtQ2dF5-BFc5L8WKoNELSjeAwuwT4kzc9lFzvtH-q4a3DHbY3D-bwMpbyKx3RjbHVYeEvfuyBHoaernTR0Lq2DlokRH0zwClq6aNFRUAYJn8OEzBGmWg265MvT9fuIeexM4eKCw/file [following]\n",
      "--2019-02-26 12:25:33--  https://ucaaab87965e7ef9e3779b987b3f.dl.dropboxusercontent.com/cd/0/inline2/AcEPDBDsJ7Th6j5GRiZQ9tjkDmhBiq-me_YmKACJtJ6BQcOxwGjIwjYrlof74gt1rzCv8Q951mDlCd6jLV6r0cWbrz2Oc_fZczOUrIBXAInLIuNYBAL-1bhlvMmMNteg43yh27RSsUTH10zXVVljW9ZU2WvsLX99bwENfnQtpMjZLaG_8qH4zsGJ2qeP6_P4lxVGmfualrJautpBtUJmEZ88QYlk5187QSnPHCtLtQ2dF5-BFc5L8WKoNELSjeAwuwT4kzc9lFzvtH-q4a3DHbY3D-bwMpbyKx3RjbHVYeEvfuyBHoaernTR0Lq2DlokRH0zwClq6aNFRUAYJn8OEzBGmWg265MvT9fuIeexM4eKCw/file\n",
      "Reusing existing connection to ucaaab87965e7ef9e3779b987b3f.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 745085878 (711M) [application/zip]\n",
      "Saving to: ‘data.zip’\n",
      "\n",
      "data.zip            100%[===================>] 710,57M  3,04MB/s    in 4m 35s  \n",
      "\n",
      "2019-02-26 12:30:08 (2,59 MB/s) - ‘data.zip’ saved [745085878/745085878]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://www.dropbox.com/s/dhpekpce05iev6a/data_v2.zip?dl=0\" -O data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qkl2cWTNszGa"
   },
   "source": [
    "Now, unzip the zip file. It contains a 'data' folder that contains three folders in turn: train, test and validation. Inside each of those there are two folders: \"hotdog\" and \"nohotdog\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "By4Yh4bLtgrE",
    "outputId": "7c34b382-7f4f-4077-d9be-f5b74af46b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12K\r\n",
      "drwxrwxr-x 4 dani dani 4,0K jun 27  2018 test\r\n",
      "drwxrwxr-x 4 dani dani 4,0K jun 27  2018 train\r\n",
      "drwxrwxr-x 4 dani dani 4,0K jun 27  2018 validation\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf data/\n",
    "!unzip -oq data.zip\n",
    "!ls -lh data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our first CNN\n",
    "\n",
    "We are going to learn some hotdogs! The basic tool we are going to use is a Convolutional Neural Network (CNN). A CNN is easy to set up in Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 118, 118, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 59, 59, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 57, 57, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1605696   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,615,905\n",
      "Trainable params: 1,615,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer, Flatten, Dense\n",
    "\n",
    "my_first_cnn = keras.Sequential()\n",
    "my_first_cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(120, 120, 3)))\n",
    "my_first_cnn.add(MaxPooling2D((2,2)))\n",
    "my_first_cnn.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "my_first_cnn.add(MaxPooling2D((2,2)))\n",
    "my_first_cnn.add(Flatten())\n",
    "my_first_cnn.add(Dense(64, activation='relu'))\n",
    "my_first_cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "my_first_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to feed the net. Create [image data generators], which will give it regularly sized images in batches of the size we specify:\n",
    "\n",
    "[image data generators]: https://keras.io/preprocessing/image/#imagedatagenerator-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4765 images belonging to 2 classes.\n",
      "Found 888 images belonging to 2 classes.\n",
      "CPU times: user 448 ms, sys: 73 ms, total: 521 ms\n",
      "Wall time: 661 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "base_dir = 'data//'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                    target_size=(120,120),\n",
    "                                                    batch_size=100,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size=(120,120),\n",
    "                                                        batch_size=100,\n",
    "                                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/validation/nohotdog | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we are ready to train! We will need to \"compile\" the net, and fit it to the images our generators will provide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 74s 2s/step - loss: 0.3996 - acc: 0.8602 - val_loss: 0.3284 - val_acc: 0.8755\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 68s 2s/step - loss: 0.3001 - acc: 0.8687 - val_loss: 0.2596 - val_acc: 0.8897\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 68s 2s/step - loss: 0.2597 - acc: 0.8904 - val_loss: 0.2577 - val_acc: 0.8856\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 79s 3s/step - loss: 0.2433 - acc: 0.8919 - val_loss: 0.2287 - val_acc: 0.9049\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 88s 3s/step - loss: 0.2228 - acc: 0.9063 - val_loss: 0.2083 - val_acc: 0.9160\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 89s 3s/step - loss: 0.2005 - acc: 0.9091 - val_loss: 0.2016 - val_acc: 0.9130\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 73s 2s/step - loss: 0.1891 - acc: 0.9143 - val_loss: 0.2185 - val_acc: 0.9150\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 83s 3s/step - loss: 0.1654 - acc: 0.9313 - val_loss: 0.1945 - val_acc: 0.9291\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 93s 3s/step - loss: 0.1408 - acc: 0.9420 - val_loss: 0.2070 - val_acc: 0.9190\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 65s 2s/step - loss: 0.1451 - acc: 0.9418 - val_loss: 0.2131 - val_acc: 0.9200\n",
      "CPU times: user 59min 17s, sys: 5min 18s, total: 1h 4min 35s\n",
      "Wall time: 12min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "my_first_cnn.compile(loss='binary_crossentropy',\n",
    "                     optimizer=Adam(lr=1e-3),\n",
    "                     metrics=['acc'])\n",
    "\n",
    "history = my_first_cnn.fit_generator(train_generator,\n",
    "                                     steps_per_epoch=30,\n",
    "                                     epochs=10,\n",
    "                                     validation_data=validation_generator,\n",
    "                                     validation_steps=10)\n",
    "\n",
    "my_first_cnn.save('my_first_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magic! In only a few minutes, we are getting a classifier with close to 90% accuracy! Time to celebrate!\n",
    "\n",
    "\n",
    "![Party!](https://thumbs.gfycat.com/AdvancedPleasedIlsamochadegu-size_restricted.gif)\n",
    "\n",
    "Let's go to bed with that sweet sweet feeling. Future Dani will take care of the cleanup. I'm sure everything is well and good with our classifier. \n",
    "\n",
    "Or is it not? We will take a closer look at how well it performs in the next installment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Reading\n",
    "\n",
    "[Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python): A great introductory book by  François Chollet, author of Keras. Explains the practice first, then goes down to theory.\n",
    "\n",
    "[Interview with François Chollet](https://www.pyimagesearch.com/2018/07/02/an-interview-with-francois-chollet/), author of DL with Python.\n",
    "\n",
    "[Implementing a Neural Network from scratch with Python](https://medium.com/@curiousily/tensorflow-for-hackers-part-iv-neural-network-from-scratch-1a4f504dfa8): An in depth view of the internal architecture of a NN, with a tutorial to implement backpropagation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
