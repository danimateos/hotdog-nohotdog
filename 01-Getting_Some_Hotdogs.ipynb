{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotdog / not hotdog\n",
    "\n",
    "\n",
    ">_What would you say if I told you there is a app on the market that tell you if you have a hotdog or not a hotdog. It is very good and I do not want to work on it any more. You can hire someone else._\n",
    ">\n",
    ">Jian-Yang, 2017\n",
    "\n",
    "I have been looking to get into Deep Learning for a while now. It's been a hugely hot topic for years now, and the libraries seem to be maturing fast. However, most initial tutorials I've found seem a little... boring. I mean, it's great to be able to recognize digits or tell cats from dogs, but what if I could [tell hotdogs from not hotdogs]? Maybe I'd package that into [iOS] and [Android] apps. And I could sell to Periscope and [become really rich, not like that conman Bachmann]!!\n",
    "\n",
    "So I embarked on just that journey: to build the best hotdog/no hotdog classifier a Data Scientist with no prior experience in Deep Learning can build. I started with getting input data, continued through building my first Convolutional Neural Network and ended up building a pretty decent classifier using some cutting edge concepts. Join me in this series of posts if you want to do the same!\n",
    "\n",
    "[tell hotdogs from not hotdogs]: https://www.youtube.com/watch?v=ACmydtFDTGs\n",
    "[become really rich, not like that conman Bachmann]: https://www.youtube.com/watch?v=AJsOA4Zl6Io\n",
    "[iOS]: https://itunes.apple.com/us/app/not-hotdog/id1212457521?mt=8\n",
    "[Android]: https://play.google.com/store/apps/details?id=com.seefoodtechnologies.nothotdog&hl=en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI, Machine Learning, Deep Learning\n",
    "\n",
    "Since you are reading this blog post, you probably are someone with a technical background in the Data Science sphere. If you already know this, bear with me because I'm going to frame the discussion a bit just so we are in the same page. You can also skip to the next section.\n",
    "\n",
    "Artificial Intelligence, AI, is a very poorly defined term. If you [Google it](https://www.google.es/search?q=artificial+intelligence+definition) you will get 'the theory and development of computer systems able to perform tasks normally requiring human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages.' If you consider that for a second, it's an ever receding horizon: as soon as some cognitive task (addition, looking up references, recognizing digits, translation..) is performed by machines routinely, it stops being AI because it isn't the exclusive province of humans anymore. So it doesn't seem very useful.\n",
    "\n",
    "[Machine Learning], ML, can be considered a subset of AI. It's just a set of algorithms that allow computers to learn rules from data. You get some tagged examples, give them to the algorithm, and voila, you have a digit recognizer, or a churn predictor, or whatever else you want (that's actually supervised machine learning, but let's not get into that).\n",
    "\n",
    "Finally, [Deep Learning] (DL), which is what most general publications are talking about these days when they talk about AI. It's a subset of ML. It uses Neural Networks, or multilayer perceptrons. These are just mathematical machines that can approximate any function, for example one that eats images of digits (matrices of 28x28 pixels) and spits out one of ten values indicating which of the digits it is. \n",
    "\n",
    "So, if it's just that, how come it's eating the world? Well, a number of trends have coalesced to push DL into extraordinary results. Some algorithmic advances, the unprecedented availability of data brought by the move of everyday life to the Internet and advances in computer power (especially, training of neural networks on GPUs) have enabled DL to outperform traditional approaches in a lot of fields: especially image classification, but also image segmentation, translation, sentiment analysis, recommendations and a lot more. The hope is that many more tasks that until now were the exclusive of humans can be automated in the near future (remember that receding horizon?), including driving a car. That last one has been overhyped in my opinion, but the power and applicability of the technique is undeniable.\n",
    "\n",
    "![The contest that started it](https://blogs.nvidia.com/wp-content/uploads/2016/06/DefenseAIPicture3-002.png)\n",
    "\n",
    "The current frenzy probably started with the [ImageNet] competition of 2012. ImageNet was a [competition] held every year in which academic teams would compete to write the algorithm that would recognize the most images from a huge standardized set. In 2012, two teams entered the competition using DL techniques and bested everyone else. As you can see in the graph, it didn't take long before everyone was using it to get unprecented results. Now it's everywhere, and we are finally going to be part of the action. \n",
    "\n",
    "[Machine Learning]: https://en.wikipedia.org/wiki/Machine_learning\n",
    "[Deep Learning]: https://en.wikipedia.org/wiki/Deep_learning\n",
    "[ImageNet]: http://image-net.org\n",
    "[competition]: http://www.image-net.org/challenges/LSVRC/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This project\n",
    "\n",
    "So let's recapitulate: we are going to build a computer program that, after being shown enough examples of hot dogs and things that are not hotdogs, will learn to tell between them. I'll guide you through each step and explain everything you need. The only prerequisites are some Python programming and a bit of general ML background.\n",
    "\n",
    "The pieces we need are:\n",
    "\n",
    "- Training images: that's what we are here for!\n",
    "- A Deep Learning Framework: [Keras]. I'd recommend installing it using [conda].\n",
    "- A computer with an NVIDIA GPU: not technically necessary, but in fact it is. \n",
    "\n",
    "The reference environment we'll be using is Linux. I honestly think it's the platform to use for data science, but if you only have Mac or Windows, do not worry. Most of the commands we'll be using are available in Mac through [homebrew], and now even in Windows through the [Windows Subsystem for Linux]. I won't be covering that, but it should be easy enough.\n",
    "\n",
    "\n",
    "Today, we'll get some training images. It's going to be a bit long, but it'll be worth it. At the end we'll have what we need to build our revolutionary hotdog/nohotdog app. Not only that; we'll have a method that will be applicable for getting training images for any classifier in the ImageNet vocabulary.\n",
    "\n",
    "[conda]: https://anaconda.org/\n",
    "[Keras]: https://keras.io/\n",
    "[homebrew]: https://brew.sh/\n",
    "[Windows Subsystem for Linux]: https://docs.microsoft.com/en-us/windows/wsl/install-win10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet\n",
    "\n",
    "We need a set of images that are hotdogs and a set of images that are __not__ hotdogs in order to be able to train our algorithm. For that we can use the ImageNet set of tagged images. The thing is, ImageNet contains more than a million images totalling around 100GB. Not only would that take a long time to download: it would be prohibitively costly to train. We are going to download only a part of it for now.\n",
    "\n",
    "For that, we need to understand how ImageNet is structured. It is based upon [WordNet], a lexical database of English. WordNet contains nouns, verbs, adjectives and adverbs grouped into _synsets_ (sets of synonyms), but ImageNet contains images corresponding only to the nouns. Each synset is identified by its wnid (WordNet id). There are actually three hotdog synsets: n07676602, n07697537, and n10187710.\n",
    "\n",
    "ImageNet doesn't own the images, so they only provide them after a registration and a request promising to use them for non-commercial research and/or educational use. However, they do provide the image urls freely, so we are going to use our downloader to get them. We will need to get the urls first. \n",
    "\n",
    "[WordNet]: https://wordnet.princeton.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the requests module to download, and os to check files.\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def download(url):\n",
    "    '''\n",
    "    Download a single freely available file if it's not already in the current directory.\n",
    "    '''\n",
    "    filename = url.split('/')[-1]\n",
    "\n",
    "    # Do not re-download: the damn website is sloooooow \n",
    "    if not os.path.exists(filename):\n",
    "    \n",
    "        # Download and write to file\n",
    "        response = requests.get(url)   \n",
    "        with open(filename, 'wb') as f: \n",
    "            f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n00001740\tentity\n",
      "n00001930\tphysical entity\n",
      "n00002137\tabstraction, abstract entity\n",
      "n00002452\tthing\n",
      "n00002684\tobject, physical object\n",
      "CPU times: user 40 ms, sys: 4 ms, total: 44 ms\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Retrieve the list of terms from the imagenet website:\n",
    "download('http://image-net.org/archive/words.txt')\n",
    "!head -n 5 words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary of wnids and terms: as easy as one dict comprehension\n",
    "with open('words.txt') as f:\n",
    "    wnids = {line.split()[0]: line.split()[1] for line in f.readlines()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wnids are overlapping, that is, there are general terms and more specific terms that are contained within them (hyponyms). The easiest way to deal with this is to just get the urls for the images we want and deduplicate them. \n",
    "\n",
    "We need two things: A list of all the image urls and a list of all hotdog urls. The ImageNet website has an api for retrieving the urls that correspond to a wnid, so we'll use that for the hotdog urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.loafnjug.com/images/hot-dog-and-tea.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://farm1.static.flickr.com/91/220588966_8350522b9a.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://farm3.static.flickr.com/2200/2252143352_1f628be218.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://farm2.static.flickr.com/1411/722638089_cd4a75d59a.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://farm4.static.flickr.com/3645/3396903223_f8601dcdd7.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "%matplotlib inline\n",
    "\n",
    "def urls_from_wnid(wnid):\n",
    "    '''Get all image urls corresponding to a single WordNet (noun) ID'''\n",
    "    \n",
    "    # The requests library encodes parameters in urls for us:\n",
    "    response = requests.get('http://www.image-net.org/api/text/imagenet.synset.geturls', params={'wnid' : wnid})\n",
    "    urls = response.content.decode('latin1').splitlines()\n",
    "    \n",
    "    return urls\n",
    "\n",
    "first_five_images = [Image(url=url, width=400) for url in urls_from_wnid('n07697537')[:5]]\n",
    "\n",
    "display(*first_five_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here a first problem: some of the links are broken. Don't worry, there are enough for our purposes.\n",
    "\n",
    "This would work also to get all images, but it would extremely slow because we are making over 80000 requests. Also because the damn imagenet site is sloooooooow. What we are going to do is use this technique to get all hotdog urls and then substract those from the complete list of urls, which is freely available from the ImageNet website as a .tgz file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 4 ms, total: 20 ms\n",
      "Wall time: 43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hotdog_wnids = {wnid for wnid, term in wnids.items() if 'hot' in term and 'dog' in term}\n",
    "hotdog_urls = {url for wnid in hotdog_wnids for url in urls_from_wnid(wnid)} # sloooooooooooooooow\n",
    "\n",
    "len(hotdog_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.48 s, sys: 1.22 s, total: 2.7 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "imagenet_fall11_urls = 'http://image-net.org/imagenet_data/urls/imagenet_fall11_urls.tgz'\n",
    "\n",
    "download(imagenet_fall11_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to build the list of all urls. We just read the file, using the `tarfile` module,  and fill the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 s, sys: 2.29 s, total: 40.2 s\n",
      "Wall time: 40.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tarfile\n",
    "\n",
    "tf = tarfile.open('imagenet_fall11_urls.tgz')\n",
    "\n",
    "# Shortcut: I know it contains a single file, so we extract the first member.\n",
    "content = tf.extractfile(tf.getmembers()[0])\n",
    "\n",
    "wnids_urls = []\n",
    "for line in content:\n",
    "    try:\n",
    "        # Split a single line at a tab\n",
    "        wnid, url = line.decode('utf-8')[:-1].split('\\t')\n",
    "    except:\n",
    "        # There are a few urls that fail; too few to worry\n",
    "        # If you want to check them out, uncomment the following line\n",
    "        # print(line)\n",
    "        pass\n",
    "        \n",
    "    wnids_urls.append((wnid, url))\n",
    "\n",
    "\n",
    "len(wnids_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaaand we have it! Just need to dedup the urls and substract the hotdog urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13023002, 1218, 13021790)\n"
     ]
    }
   ],
   "source": [
    "# Some urls might be duplicated; dedup by using a set comprehension\n",
    "# You can tell I really like comprehensions in python, can't you?\n",
    "all_urls = {url for wnid, url in wnids_urls}\n",
    "\n",
    "# We already have the hotdog urls from before\n",
    "other_urls = all_urls - hotdog_urls\n",
    "\n",
    "print((len(all_urls), len(hotdog_urls), len(other_urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaaaand from that, we are going to choose a sample of hotdogs and not hotdogs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "hotdogs_sample = random.sample(hotdog_urls, 1216) # Use all of themfor now\n",
    "nohotdogs_sample = random.sample(other_urls, k=10000) # Let's get as many as we can without overunbalancing the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write them down so we don't lose them, and we can use the lists from outside python some other day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hotdogs_sample.txt', 'w') as f:\n",
    "    f.write('\\n'.join(hotdogs_sample))\n",
    "    \n",
    "with open('nohotdogs_sample.txt', 'w') as f:\n",
    "    f.write('\\n'.join(nohotdogs_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! we have our images! More exactly, we have two lists of urls. That's fine, because downloading them and setting them in the proper folder structure is a one-hour job. However, this post is long enough as it is, so I'll show you how to do that next time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Links\n",
    "\n",
    "[imagenet-downloader](https://github.com/xkumiyu/imagenet-downloader/)\n",
    "\n",
    "http://image-net.org/synset?wnid=n07697537\n",
    "\n",
    "http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n07697537\n",
    "\n",
    "http://caffe.berkeleyvision.org/gathered/examples/imagenet.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
